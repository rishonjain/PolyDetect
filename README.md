# ğŸ§  PolyDetect â€” Multilingual AI-Generated Text Detector  
**A GPU-accelerated hybrid detector for AI-generated text across 5 languages (EN/ES/DE/RU/ZH).**  
Combines transformer embeddings (XLM-R, MiniLM, mBERT, DistilBERT) with statistical-lexical cues and classical ML models.

---

## ğŸš€ Features

### **Multilingual Support**
- English  
- Spanish  
- German  
- Russian  
- Chinese  

### **Hybrid Detection Architecture**
PolyDetect uses a combination of:
- **Transformer embeddings** (XLM-R / MiniLM / BERT / DistilBERT)
- **Perplexity** (DistilGPT-2)
- **Lexical diversity**
- **Classical ML models**
  - XGBoost (GPU-accelerated)
  - Logistic Regression  
  - Random Forest  
  - SVM  
  - FFNN (MLPClassifier)

### **Model Formats**
Each trained model saves:
- `polydetect_{encoder}_{clf}.joblib`
- `polydetect_{encoder}_{clf}.meta.json`
- `{encoder}_global_scaler.pkl`

This guarantees **100% reproducible** inference.

### **GPU Optimization**
- Embeddings â†’ **GPU**
- XGBoost â†’ **GPU** (if available)
- Perplexity â†’ **CPU** (avoids Windows CUDA deadlocks)
- Automatic fallback to CPU when GPU not available.

---

## ğŸ— Project Structure

```
PolyDetect/
â”‚
â”œâ”€â”€ app.py                      # Streamlit frontend (GPU-enabled)
â”œâ”€â”€ inference.py                # Generates CM & ROC (GPU)
â”œâ”€â”€ evaluation.py               # Language-wise evaluation â†’ metrics/
â”‚
â”œâ”€â”€ train_xlmr.py               # Train XLM-R models
â”œâ”€â”€ train_minilm_multilingual.py
â”œâ”€â”€ train_bert_multilingual.py
â”œâ”€â”€ train_distilbert_multilingual.py
â”‚
â”œâ”€â”€ models/                     # Encoder folders + generated classifiers
â”‚   â”œâ”€â”€ xlm-roberta-base/
â”‚   â”œâ”€â”€ microsoft-MiniLM-L12-H384/
â”‚   â”œâ”€â”€ distilgpt2/
â”‚   â”œâ”€â”€ bert-base-multilingual-cased/
â”‚   â”œâ”€â”€ distilbert-base-multilingual-cased/
â”‚   â”œâ”€â”€ polydetect_xlmr_xgboost.joblib
â”‚   â”œâ”€â”€ ...
â”‚
â”œâ”€â”€ metrics/                    # NEW (metrics CSVs stored here)
â”‚   â”œâ”€â”€ metrics_combined.csv
â”‚   â”œâ”€â”€ metrics_language.csv
â”‚
â”œâ”€â”€ confusion_matrices/         # Generated CM pngs
â”œâ”€â”€ roc_curves/                 # Generated ROC pngs
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ multitude_v3_clean.csv
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš¡ Installation

### 1. Clone the repository

```bash
git clone https://github.com/<your-username>/PolyDetect
cd PolyDetect
```

### 2. Install dependencies

GPU-enabled PyTorch (CUDA 11.8):

```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

Then install everything else:

```bash
pip install -r requirements.txt
```

---

## ğŸ§ª Training All Models

Each training script automatically:
- Computes features  
- Runs embeddings on GPU  
- Runs perplexity on CPU  
- Saves scaler + metadata  
- Trains 5 different classifiers  

Example:

```bash
python train_xlmr.py
python train_minilm_multilingual.py
python train_bert_multilingual.py
python train_distilbert_multilingual.py
```

---

## ğŸ“Š Evaluation

To create:
- confusion_matrices/
- roc_curves/
- metrics/metrics_combined.csv
- metrics/metrics_language.csv

Run:

```bash
python evaluation.py
```

---

## ğŸ› Running Streamlit App

```bash
streamlit run app.py
```

---

## ğŸ§© Model Metadata Structure

Every model has a JSON metadata file:

```json
{
  "encoder": "minilm",
  "embedding_dim": 384,
  "feature_order": ["perplexity", "diversity", "embedding"],
  "feature_dim": 386
}
```

This ensures the correct encoder, scaler, and feature pipeline are used during inference.

---

## ğŸ§  Live Inference (API-Ready)

```python
from inference import predict_text

prob = predict_text("your text here", model="polydetect_minilm_xgboost")
print(prob)
```

---

## ğŸ›¡ Safety Notes

Perplexity is always computed on **CPU** due to instability of GPT-2 pipeline on CUDA/Windows.  
Embeddings always run on **GPU** for speed.

---

## ğŸ“„ License
MIT License.

---

## ğŸ‘¨â€ğŸ’» Authors
- Rishon Jain (Lead Engineer, Researcher)
- PolyDetect Research Team (Bennett University)
